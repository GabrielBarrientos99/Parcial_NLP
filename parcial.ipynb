{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGUNTA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['all models are wrong',\n",
    "             'a model is wrong',\n",
    "             'some models are useful']\n",
    "\n",
    "vocab= ['<s>','</s>','a','all','are','model','some','useful','wrong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'models', 'are', 'wrong', 'a', 'model', 'is', 'wrong', 'some', 'models', 'are', 'useful']\n"
     ]
    }
   ],
   "source": [
    "# a) Calcular todas las probabilidades\n",
    "# de los bigramas sin suavisado\n",
    "import re\n",
    "\n",
    "def getFreqBigramas_Unigrams(sentence:str)->dict:\n",
    "    # Tokenizamos la oración (un split simple)\n",
    "    pattern = re.compile(r'\\b\\w+\\b')\n",
    "    words_tokenized = pattern.findall(sentence)\n",
    "    print(words_tokenized)\n",
    "    bigrams = {}\n",
    "    unigrams = {}\n",
    "    for word in words_tokenized:\n",
    "        n = len(word)        \n",
    "        for i in range(n-1):\n",
    "            bigram = (word[i],word[i+1])\n",
    "            unigram = word[i]\n",
    "            if bigram not in bigrams:\n",
    "                bigrams[bigram]=1\n",
    "            else:\n",
    "                bigrams[bigram]+=1\n",
    "            if unigram not in unigrams:\n",
    "                unigrams[unigram]=1\n",
    "            else:\n",
    "                unigrams[unigram]+=1\n",
    "        \n",
    "\n",
    "        # Añadimos el ultimo unigram\n",
    "        last_unigram = word[-1]\n",
    "        if last_unigram not in unigrams:\n",
    "            unigrams[last_unigram]=1\n",
    "        else:\n",
    "            unigrams[last_unigram]+=1\n",
    "\n",
    "    return bigrams,unigrams\n",
    "\n",
    "def getProbBigrams(bigrams:dict,unigrams:dict)->dict:\n",
    "    prob_bigrams = {}\n",
    "    \n",
    "    for bigram,freq in bigrams.items():\n",
    "        prob_bigrams[bigram] = (freq)/(unigrams[bigram[0]])\n",
    "    return prob_bigrams\n",
    "\n",
    "\n",
    "text = '. '.join(sentences)\n",
    "\n",
    "bigrams,unigrams = getFreqBigramas_Unigrams(text)\n",
    "\n",
    "prob= getProbBigrams(bigrams,unigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 1,\n",
       " ('l', 'l'): 1,\n",
       " ('m', 'o'): 3,\n",
       " ('o', 'd'): 3,\n",
       " ('d', 'e'): 3,\n",
       " ('e', 'l'): 3,\n",
       " ('l', 's'): 2,\n",
       " ('a', 'r'): 2,\n",
       " ('r', 'e'): 2,\n",
       " ('w', 'r'): 2,\n",
       " ('r', 'o'): 2,\n",
       " ('o', 'n'): 2,\n",
       " ('n', 'g'): 2,\n",
       " ('i', 's'): 1,\n",
       " ('s', 'o'): 1,\n",
       " ('o', 'm'): 1,\n",
       " ('m', 'e'): 1,\n",
       " ('u', 's'): 1,\n",
       " ('s', 'e'): 1,\n",
       " ('e', 'f'): 1,\n",
       " ('f', 'u'): 1,\n",
       " ('u', 'l'): 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.25,\n",
       " ('l', 'l'): 0.16666666666666666,\n",
       " ('m', 'o'): 0.75,\n",
       " ('o', 'd'): 0.5,\n",
       " ('d', 'e'): 1.0,\n",
       " ('e', 'l'): 0.42857142857142855,\n",
       " ('l', 's'): 0.3333333333333333,\n",
       " ('a', 'r'): 0.5,\n",
       " ('r', 'e'): 0.5,\n",
       " ('w', 'r'): 1.0,\n",
       " ('r', 'o'): 0.5,\n",
       " ('o', 'n'): 0.3333333333333333,\n",
       " ('n', 'g'): 1.0,\n",
       " ('i', 's'): 1.0,\n",
       " ('s', 'o'): 0.2,\n",
       " ('o', 'm'): 0.16666666666666666,\n",
       " ('m', 'e'): 0.25,\n",
       " ('u', 's'): 0.5,\n",
       " ('s', 'e'): 0.2,\n",
       " ('e', 'f'): 0.14285714285714285,\n",
       " ('f', 'u'): 1.0,\n",
       " ('u', 'l'): 0.5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculando las probabilidades sin suavisado\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suavizado add-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suavizado add-k\n",
    "# Suavizado Add-k para unigramas\n",
    "def add_k_smoothing_unigram(bigrams,unigrams, k):\n",
    "\n",
    "    # Número total de tokens en el corpus\n",
    "    N = sum(unigrams.values())\n",
    "\n",
    "    # Tamaño del vocabulario\n",
    "    V = len(unigrams)\n",
    "\n",
    "    # Cálculo de las probabilidades suavizadas\n",
    "    add_k_probabilities = {}\n",
    "    for bigram, freq in bigrams.items():\n",
    "        # Aplicando la ecuación P_Add-k(w_i) = (c_i + k) / (N + kV)\n",
    "        add_k_probabilities[bigram] = (freq + k) / (N + k * V)\n",
    "    \n",
    "    # Probabilidad para una palabra no vista\n",
    "    add_k_probabilities['<UNK>'] = k / (N + k * V)\n",
    "    \n",
    "    return add_k_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.031746031746031744,\n",
       " ('l', 'l'): 0.031746031746031744,\n",
       " ('m', 'o'): 0.06349206349206349,\n",
       " ('o', 'd'): 0.06349206349206349,\n",
       " ('d', 'e'): 0.06349206349206349,\n",
       " ('e', 'l'): 0.06349206349206349,\n",
       " ('l', 's'): 0.047619047619047616,\n",
       " ('a', 'r'): 0.047619047619047616,\n",
       " ('r', 'e'): 0.047619047619047616,\n",
       " ('w', 'r'): 0.047619047619047616,\n",
       " ('r', 'o'): 0.047619047619047616,\n",
       " ('o', 'n'): 0.047619047619047616,\n",
       " ('n', 'g'): 0.047619047619047616,\n",
       " ('i', 's'): 0.031746031746031744,\n",
       " ('s', 'o'): 0.031746031746031744,\n",
       " ('o', 'm'): 0.031746031746031744,\n",
       " ('m', 'e'): 0.031746031746031744,\n",
       " ('u', 's'): 0.031746031746031744,\n",
       " ('s', 'e'): 0.031746031746031744,\n",
       " ('e', 'f'): 0.031746031746031744,\n",
       " ('f', 'u'): 0.031746031746031744,\n",
       " ('u', 'l'): 0.031746031746031744,\n",
       " '<UNK>': 0.015873015873015872}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Calcular las probabilidades para k = 1\n",
    "prob_add_one = add_k_smoothing_unigram(bigrams,unigrams,k=1)\n",
    "prob_add_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Calcular las probabilidades para k=0.05,0.15\n",
    "prob_add_1= add_k_smoothing_unigram(bigrams,unigrams,k=0.05)\n",
    "prob_add_2 = add_k_smoothing_unigram(bigrams,unigrams,k=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.02112676056338028,\n",
       " ('l', 'l'): 0.02112676056338028,\n",
       " ('m', 'o'): 0.06136820925553319,\n",
       " ('o', 'd'): 0.06136820925553319,\n",
       " ('d', 'e'): 0.06136820925553319,\n",
       " ('e', 'l'): 0.06136820925553319,\n",
       " ('l', 's'): 0.04124748490945673,\n",
       " ('a', 'r'): 0.04124748490945673,\n",
       " ('r', 'e'): 0.04124748490945673,\n",
       " ('w', 'r'): 0.04124748490945673,\n",
       " ('r', 'o'): 0.04124748490945673,\n",
       " ('o', 'n'): 0.04124748490945673,\n",
       " ('n', 'g'): 0.04124748490945673,\n",
       " ('i', 's'): 0.02112676056338028,\n",
       " ('s', 'o'): 0.02112676056338028,\n",
       " ('o', 'm'): 0.02112676056338028,\n",
       " ('m', 'e'): 0.02112676056338028,\n",
       " ('u', 's'): 0.02112676056338028,\n",
       " ('s', 'e'): 0.02112676056338028,\n",
       " ('e', 'f'): 0.02112676056338028,\n",
       " ('f', 'u'): 0.02112676056338028,\n",
       " ('u', 'l'): 0.02112676056338028,\n",
       " '<UNK>': 0.001006036217303823}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_add_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.022504892367906065,\n",
       " ('l', 'l'): 0.022504892367906065,\n",
       " ('m', 'o'): 0.06164383561643835,\n",
       " ('o', 'd'): 0.06164383561643835,\n",
       " ('d', 'e'): 0.06164383561643835,\n",
       " ('e', 'l'): 0.06164383561643835,\n",
       " ('l', 's'): 0.04207436399217221,\n",
       " ('a', 'r'): 0.04207436399217221,\n",
       " ('r', 'e'): 0.04207436399217221,\n",
       " ('w', 'r'): 0.04207436399217221,\n",
       " ('r', 'o'): 0.04207436399217221,\n",
       " ('o', 'n'): 0.04207436399217221,\n",
       " ('n', 'g'): 0.04207436399217221,\n",
       " ('i', 's'): 0.022504892367906065,\n",
       " ('s', 'o'): 0.022504892367906065,\n",
       " ('o', 'm'): 0.022504892367906065,\n",
       " ('m', 'e'): 0.022504892367906065,\n",
       " ('u', 's'): 0.022504892367906065,\n",
       " ('s', 'e'): 0.022504892367906065,\n",
       " ('e', 'f'): 0.022504892367906065,\n",
       " ('f', 'u'): 0.022504892367906065,\n",
       " ('u', 'l'): 0.022504892367906065,\n",
       " '<UNK>': 0.0029354207436399216}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_add_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backoff y stupid Backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
