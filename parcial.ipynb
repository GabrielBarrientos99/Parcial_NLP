{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREGUNTA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['all models are wrong',\n",
    "             'a model is wrong',\n",
    "             'some models are useful']\n",
    "\n",
    "vocab= ['<s>','</s>','a','all','are','model','some','useful','wrong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'models', 'are', 'wrong', 'a', 'model', 'is', 'wrong', 'some', 'models', 'are', 'useful']\n"
     ]
    }
   ],
   "source": [
    "# a) Calcular todas las probabilidades\n",
    "# de los bigramas sin suavisado\n",
    "import re\n",
    "\n",
    "def getFreqBigramas_Unigrams(sentence:str)->dict:\n",
    "    # Tokenizamos la oración (un split simple)\n",
    "    pattern = re.compile(r'\\b\\w+\\b')\n",
    "    words_tokenized = pattern.findall(sentence)\n",
    "    print(words_tokenized)\n",
    "    bigrams = {}\n",
    "    unigrams = {}\n",
    "    for word in words_tokenized:\n",
    "        n = len(word)        \n",
    "        for i in range(n-1):\n",
    "            bigram = (word[i],word[i+1])\n",
    "            unigram = word[i]\n",
    "            if bigram not in bigrams:\n",
    "                bigrams[bigram]=1\n",
    "            else:\n",
    "                bigrams[bigram]+=1\n",
    "            if unigram not in unigrams:\n",
    "                unigrams[unigram]=1\n",
    "            else:\n",
    "                unigrams[unigram]+=1\n",
    "        \n",
    "\n",
    "        # Añadimos el ultimo unigram\n",
    "        last_unigram = word[-1]\n",
    "        if last_unigram not in unigrams:\n",
    "            unigrams[last_unigram]=1\n",
    "        else:\n",
    "            unigrams[last_unigram]+=1\n",
    "\n",
    "    return bigrams,unigrams\n",
    "\n",
    "def getProbBigrams(bigrams:dict,unigrams:dict)->dict:\n",
    "    prob_bigrams = {}\n",
    "    \n",
    "    for bigram,freq in bigrams.items():\n",
    "        prob_bigrams[bigram] = (freq)/(unigrams[bigram[0]])\n",
    "    return prob_bigrams\n",
    "\n",
    "\n",
    "text = '. '.join(sentences)\n",
    "\n",
    "bigrams,unigrams = getFreqBigramas_Unigrams(text)\n",
    "\n",
    "prob= getProbBigrams(bigrams,unigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 1,\n",
       " ('l', 'l'): 1,\n",
       " ('m', 'o'): 3,\n",
       " ('o', 'd'): 3,\n",
       " ('d', 'e'): 3,\n",
       " ('e', 'l'): 3,\n",
       " ('l', 's'): 2,\n",
       " ('a', 'r'): 2,\n",
       " ('r', 'e'): 2,\n",
       " ('w', 'r'): 2,\n",
       " ('r', 'o'): 2,\n",
       " ('o', 'n'): 2,\n",
       " ('n', 'g'): 2,\n",
       " ('i', 's'): 1,\n",
       " ('s', 'o'): 1,\n",
       " ('o', 'm'): 1,\n",
       " ('m', 'e'): 1,\n",
       " ('u', 's'): 1,\n",
       " ('s', 'e'): 1,\n",
       " ('e', 'f'): 1,\n",
       " ('f', 'u'): 1,\n",
       " ('u', 'l'): 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.25,\n",
       " ('l', 'l'): 0.16666666666666666,\n",
       " ('m', 'o'): 0.75,\n",
       " ('o', 'd'): 0.5,\n",
       " ('d', 'e'): 1.0,\n",
       " ('e', 'l'): 0.42857142857142855,\n",
       " ('l', 's'): 0.3333333333333333,\n",
       " ('a', 'r'): 0.5,\n",
       " ('r', 'e'): 0.5,\n",
       " ('w', 'r'): 1.0,\n",
       " ('r', 'o'): 0.5,\n",
       " ('o', 'n'): 0.3333333333333333,\n",
       " ('n', 'g'): 1.0,\n",
       " ('i', 's'): 1.0,\n",
       " ('s', 'o'): 0.2,\n",
       " ('o', 'm'): 0.16666666666666666,\n",
       " ('m', 'e'): 0.25,\n",
       " ('u', 's'): 0.5,\n",
       " ('s', 'e'): 0.2,\n",
       " ('e', 'f'): 0.14285714285714285,\n",
       " ('f', 'u'): 1.0,\n",
       " ('u', 'l'): 0.5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculando las probabilidades sin suavisado\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suavizado add-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suavizado add-k\n",
    "# Suavizado Add-k para unigramas\n",
    "def add_k_smoothing_unigram(bigrams,unigrams, k):\n",
    "\n",
    "    # Número total de tokens en el corpus\n",
    "    N = sum(unigrams.values())\n",
    "\n",
    "    # Tamaño del vocabulario\n",
    "    V = len(unigrams)\n",
    "\n",
    "    # Cálculo de las probabilidades suavizadas\n",
    "    add_k_probabilities = {}\n",
    "    for bigram, freq in bigrams.items():\n",
    "        # Aplicando la ecuación P_Add-k(w_i) = (c_i + k) / (N + kV)\n",
    "        add_k_probabilities[bigram] = (freq + k) / (N + k * V)\n",
    "    \n",
    "    # Probabilidad para una palabra no vista\n",
    "    add_k_probabilities['<UNK>'] = k / (N + k * V)\n",
    "    \n",
    "    return add_k_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.031746031746031744,\n",
       " ('l', 'l'): 0.031746031746031744,\n",
       " ('m', 'o'): 0.06349206349206349,\n",
       " ('o', 'd'): 0.06349206349206349,\n",
       " ('d', 'e'): 0.06349206349206349,\n",
       " ('e', 'l'): 0.06349206349206349,\n",
       " ('l', 's'): 0.047619047619047616,\n",
       " ('a', 'r'): 0.047619047619047616,\n",
       " ('r', 'e'): 0.047619047619047616,\n",
       " ('w', 'r'): 0.047619047619047616,\n",
       " ('r', 'o'): 0.047619047619047616,\n",
       " ('o', 'n'): 0.047619047619047616,\n",
       " ('n', 'g'): 0.047619047619047616,\n",
       " ('i', 's'): 0.031746031746031744,\n",
       " ('s', 'o'): 0.031746031746031744,\n",
       " ('o', 'm'): 0.031746031746031744,\n",
       " ('m', 'e'): 0.031746031746031744,\n",
       " ('u', 's'): 0.031746031746031744,\n",
       " ('s', 'e'): 0.031746031746031744,\n",
       " ('e', 'f'): 0.031746031746031744,\n",
       " ('f', 'u'): 0.031746031746031744,\n",
       " ('u', 'l'): 0.031746031746031744,\n",
       " '<UNK>': 0.015873015873015872}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Calcular las probabilidades para k = 1\n",
    "prob_add_one = add_k_smoothing_unigram(bigrams,unigrams,k=1)\n",
    "prob_add_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Calcular las probabilidades para k=0.05,0.15\n",
    "prob_add_1= add_k_smoothing_unigram(bigrams,unigrams,k=0.05)\n",
    "prob_add_2 = add_k_smoothing_unigram(bigrams,unigrams,k=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.02112676056338028,\n",
       " ('l', 'l'): 0.02112676056338028,\n",
       " ('m', 'o'): 0.06136820925553319,\n",
       " ('o', 'd'): 0.06136820925553319,\n",
       " ('d', 'e'): 0.06136820925553319,\n",
       " ('e', 'l'): 0.06136820925553319,\n",
       " ('l', 's'): 0.04124748490945673,\n",
       " ('a', 'r'): 0.04124748490945673,\n",
       " ('r', 'e'): 0.04124748490945673,\n",
       " ('w', 'r'): 0.04124748490945673,\n",
       " ('r', 'o'): 0.04124748490945673,\n",
       " ('o', 'n'): 0.04124748490945673,\n",
       " ('n', 'g'): 0.04124748490945673,\n",
       " ('i', 's'): 0.02112676056338028,\n",
       " ('s', 'o'): 0.02112676056338028,\n",
       " ('o', 'm'): 0.02112676056338028,\n",
       " ('m', 'e'): 0.02112676056338028,\n",
       " ('u', 's'): 0.02112676056338028,\n",
       " ('s', 'e'): 0.02112676056338028,\n",
       " ('e', 'f'): 0.02112676056338028,\n",
       " ('f', 'u'): 0.02112676056338028,\n",
       " ('u', 'l'): 0.02112676056338028,\n",
       " '<UNK>': 0.001006036217303823}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_add_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.022504892367906065,\n",
       " ('l', 'l'): 0.022504892367906065,\n",
       " ('m', 'o'): 0.06164383561643835,\n",
       " ('o', 'd'): 0.06164383561643835,\n",
       " ('d', 'e'): 0.06164383561643835,\n",
       " ('e', 'l'): 0.06164383561643835,\n",
       " ('l', 's'): 0.04207436399217221,\n",
       " ('a', 'r'): 0.04207436399217221,\n",
       " ('r', 'e'): 0.04207436399217221,\n",
       " ('w', 'r'): 0.04207436399217221,\n",
       " ('r', 'o'): 0.04207436399217221,\n",
       " ('o', 'n'): 0.04207436399217221,\n",
       " ('n', 'g'): 0.04207436399217221,\n",
       " ('i', 's'): 0.022504892367906065,\n",
       " ('s', 'o'): 0.022504892367906065,\n",
       " ('o', 'm'): 0.022504892367906065,\n",
       " ('m', 'e'): 0.022504892367906065,\n",
       " ('u', 's'): 0.022504892367906065,\n",
       " ('s', 'e'): 0.022504892367906065,\n",
       " ('e', 'f'): 0.022504892367906065,\n",
       " ('f', 'u'): 0.022504892367906065,\n",
       " ('u', 'l'): 0.022504892367906065,\n",
       " '<UNK>': 0.0029354207436399216}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_add_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backoff y stupid Backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff_unigram(unigram_counts, total_tokens):\n",
    "    # Calcula las probabilidades de unigramas\n",
    "    unigram_probs = {}\n",
    "    for word, count in unigram_counts.items():\n",
    "        unigram_probs[word] = count / total_tokens\n",
    "    return unigram_probs\n",
    "\n",
    "def backoff_bigram(bigram_counts, unigram_counts, total_tokens):\n",
    "    # Calcula las probabilidades de bigramas con retroceso a unigramas\n",
    "    bigram_probs = {}\n",
    "    for (w1, w2), count in bigram_counts.items():\n",
    "        if unigram_counts[w1] > 0:\n",
    "            bigram_probs[(w1, w2)] = count / unigram_counts[w1]\n",
    "        else:\n",
    "            bigram_probs[(w1, w2)] = backoff_unigram(unigram_counts, total_tokens).get(w2, 1 / total_tokens)\n",
    "    return bigram_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'l'): 0.25,\n",
       " ('l', 'l'): 0.16666666666666666,\n",
       " ('m', 'o'): 0.75,\n",
       " ('o', 'd'): 0.5,\n",
       " ('d', 'e'): 1.0,\n",
       " ('e', 'l'): 0.42857142857142855,\n",
       " ('l', 's'): 0.3333333333333333,\n",
       " ('a', 'r'): 0.5,\n",
       " ('r', 'e'): 0.5,\n",
       " ('w', 'r'): 1.0,\n",
       " ('r', 'o'): 0.5,\n",
       " ('o', 'n'): 0.3333333333333333,\n",
       " ('n', 'g'): 1.0,\n",
       " ('i', 's'): 1.0,\n",
       " ('s', 'o'): 0.2,\n",
       " ('o', 'm'): 0.16666666666666666,\n",
       " ('m', 'e'): 0.25,\n",
       " ('u', 's'): 0.5,\n",
       " ('s', 'e'): 0.2,\n",
       " ('e', 'f'): 0.14285714285714285,\n",
       " ('f', 'u'): 1.0,\n",
       " ('u', 'l'): 0.5}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(unigrams)\n",
    "backoff_prob = backoff_bigram(bigrams,unigrams,n)\n",
    "backoff_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import collections\n",
    "from typing import List, Tuple, Dict\n",
    "class NGramModel:\n",
    "    def __init__(self, n: int):\n",
    "        self.n = n\n",
    "        self.ngram_counts = collections.Counter()\n",
    "        self.context_counts = collections.Counter()\n",
    "        self.vocab = set()\n",
    "        self.total_ngrams = 0\n",
    "\n",
    "    def train(self, corpus: List[List[str]]):\n",
    "        for document in corpus:\n",
    "            tokens = ['<s>'] * (self.n - 1) + document + ['</s>']\n",
    "            self.vocab.update(tokens)\n",
    "            for i in range(len(tokens) - self.n + 1):\n",
    "                ngram = tuple(tokens[i:i + self.n])\n",
    "                context = tuple(tokens[i:i + self.n - 1])\n",
    "                self.ngram_counts[ngram] += 1\n",
    "                self.context_counts[context] += 1\n",
    "                self.total_ngrams += 1\n",
    "\n",
    "    def get_ngram_prob(self, ngram: Tuple[str, ...]) -> float:\n",
    "        count = self.ngram_counts.get(ngram, 0)\n",
    "        context = ngram[:-1]\n",
    "        context_count = self.context_counts.get(context, 0)\n",
    "        if context_count == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return count / context_count\n",
    "\n",
    "    def get_sentence_probability(self, sentence: List[str]) -> float:\n",
    "        tokens = ['<s>'] * (self.n - 1) + sentence + ['</s>']\n",
    "        probability = 1.0\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            ngram = tuple(tokens[i:i + self.n])\n",
    "            prob = self.get_ngram_prob(ngram)\n",
    "            if prob > 0:\n",
    "                probability *= prob\n",
    "            else:\n",
    "                # Asignamos una pequeña probabilidad para evitar cero\n",
    "                probability *= 1e-6\n",
    "        return probability\n",
    "    \n",
    "# Implementación del Stupid Backoff\n",
    "class StupidBackoffNGramModel(NGramModel):\n",
    "    def __init__(self, n: int, models: List[NGramModel], alpha: float = 0.4):\n",
    "        super().__init__(n)\n",
    "        self.models = models  # Lista de modelos de diferentes órdenes, ordenados de mayor a menor\n",
    "        self.alpha = alpha    # Factor de escala fijo\n",
    "        # Actualizamos self.vocab con la unión de los vocabularios de los modelos\n",
    "        self.vocab = set()\n",
    "        for model in self.models:\n",
    "            self.vocab.update(model.vocab)\n",
    "\n",
    "    def get_ngram_prob(self, ngram: Tuple[str, ...]) -> float:\n",
    "        for i, model in enumerate(self.models):\n",
    "            ngram_adjusted = ngram[-model.n:]\n",
    "            prob = model.get_ngram_prob(ngram_adjusted)\n",
    "            if prob > 0:\n",
    "                return (self.alpha ** i) * prob\n",
    "        # Si ningún modelo tiene el n-grama, asignamos una pequeña probabilidad\n",
    "        return (self.alpha ** len(self.models)) * (1.0 / len(self.vocab))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['all', 'models', 'are', 'wrong'], ['a', 'model', 'is', 'wrong'], ['some', 'models', 'are', 'useful']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.StupidBackoffNGramModel at 0x22d24955c50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesamos el text\n",
    "sentences = ['all models are wrong',\n",
    "             'a model is wrong',\n",
    "             'some models are useful']\n",
    "\n",
    "corpus = []\n",
    "for s in sentences:\n",
    "    corpus_tokenized = s.split()\n",
    "    corpus.append(corpus_tokenized)\n",
    "print(corpus)\n",
    "\n",
    "# Entrenamos modelos base\n",
    "unigram_model = NGramModel(n=1)\n",
    "bigram_model = NGramModel(n=2)\n",
    "trigram_model = NGramModel(n=3)\n",
    "\n",
    "unigram_model.train(corpus )\n",
    "bigram_model.train(corpus )\n",
    "\n",
    "# Modelo Stupid Backoff\n",
    "stupid_backoff_model = StupidBackoffNGramModel(n=3, models=[trigram_model, bigram_model, unigram_model], alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del texto: 6103 caracteres\n",
      "\n",
      "Comunicado:\n",
      "\n",
      "Había sido advertido. Y antes de nuestro tiempo otros compañeros habían hecho esta misma advertencia. La tranquilidad del mundo que construyen defensores y administradores de este orden\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del texto: 6103 caracteres\n",
      "\n",
      "Comunicado:\n",
      "\n",
      "Había sido advertido. Y antes de nuestro tiempo otros compañeros habían hecho esta misma advertencia. La tranquilidad del mundo que construyen defensores y administradores de este orden\n"
     ]
    }
   ],
   "source": [
    "# Lectura del corpus\n",
    "texto = open('comunicado_ejemplo.txt', 'rb').read().decode(encoding='utf-8')\n",
    "print ('Tamaño del texto: {} caracteres'.format(len(texto)))\n",
    "print ()\n",
    "print (texto[:200])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
